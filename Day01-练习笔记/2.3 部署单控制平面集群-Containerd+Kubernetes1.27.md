# **1. 部署单控制平面集群**



[TOC]

## **1. 1 基础环境准备**

### **1.1.1 硬件准备**

机器配置：2核CPU，4G内存，40G系统盘

系统：Ubuntu 20.04

机器数量：3台 （master01	node01	node02）



### **1.1.2 系统环境配置**

修改配置静态hostname

```shell
hostnamectl set-hostname master01 --static
```



修改hosts表,集群所有节点保持文件内容一致

```shell
#Kubernetes
172.31.53.87    master01
172.31.53.88    node01
172.31.53.86    node02
```



配置服务器时间统一



关闭firewalld

```shell
ufw disable
```



关闭SELinux

```shell
ubuntu默认关闭SELinux
```



关闭swap

```shell
 # 临时关闭
 	swapoff -a

 # 永久关闭
 	注释掉/etc/fstab下的swap一行
```



 开启参数自动补全,取消bash-completion注释

```shell
vim /etc/bash.bashrc
# enable bash completion in interactive shells
if ! shopt -oq posix; then
  if [ -f /usr/share/bash-completion/bash_completion ]; then
    . /usr/share/bash-completion/bash_completion
  elif [ -f /etc/bash_completion ]; then
    . /etc/bash_completion
  fi
fi
source /etc/bash.bashrc
```



### **1.1.3 Containerd环境准备**

```shell
# 访问GitHub查询Containerd最新版本
wget https://github.com/containerd/containerd/releases/

# 下载
cd /root ; wget https://github.com/containerd/containerd/releases/download/v1.6.4/cri-containerd-1.6.4-linux-amd64.tar.gz

# 查看压缩包里的文件内容
tar -tf cri-containerd-cni-1.6.4-linux-amd64.tar.gz
# 解压缩containerd安装包
cd /root ; tar -xvf cri-containerd-cni-1.6.4-linux-amd64.tar.gz -C /

# 生成containerd的配置文件
mkdir /etc/containerd ; containerd config default > /etc/containerd/config.toml

# config.toml内容讲解   cat /etc/containerd/config.toml
  version =2 ：这个是新本版基本默认的选项。
  root：containerd保存元数据的地方。
  state: containerd的状态目录，重启数据就会刷新，就一个临时目录。
  address: 这个指的是containerd监听的套接字。
  plugins: 其中sandbox_image配置的是cni的插件，
  以及配置的cni的二进制目录和初始化目录；还有配置的私有库的地址，证书，访问的用户密码
  path: container的二进制文件路径
  interval:containerd重启的时间间隔
  runtime：这部分配置需要的运行时runc,containerd-shim这个垫片可以选择用或者不用

# 将sandbox_image镜像源设置为阿里云下载,文件的第61行
sed -i "s#k8s.gcr.io/pause#registry.cn-hangzhou.aliyuncs.com/google_containers/pause#g"  /etc/containerd/config.toml

# 设置阿里云镜像加速，文件的第153行
sed -i '/registry.mirrors]/a\ \ \ \ \ \ \ \ [plugins."io.containerd.grpc.v1.cri".registry.mirrors."docker.io"]' /etc/containerd/config.toml
sed -i '/registry.mirrors."docker.io"]/a\ \ \ \ \ \ \ \ \ \ endpoint = ["https://x868aafl.mirror.aliyuncs.com"]' /etc/containerd/config.toml 

# 设置containerd的Cgroup drivers为systemd,文件的第125行
sed -i 's#SystemdCgroup = false#SystemdCgroup = true#g' /etc/containerd/config.toml

# 启动containerd
systemctl enable --now containerd.service ; systemctl status containerd.service
```



### **1.1.4 kubeadm环境准备**

配置apt库，安装kubeadm、kubelet、kubectl

```shell
apt-get update && apt-get install -y apt-transport-https
curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - 
cat <<EOF >/etc/apt/sources.list.d/kubernetes.list
deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main
EOF
apt-get update
apt-get install -y kubelet kubeadm kubectl
```



开启这些设置使通过网桥的数据包由主机系统上的iptables规则处理，默认关闭，设置为1则开启

```shell
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

# sysctl params required by setup, params persist across reboots
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

# Apply sysctl params without reboot
sudo sysctl --system
```



## **1.2 创建单控制平面集群**

### **1.2.1 初始化集群**

命令详解

kubeadm config upload from-file：由配置文件上传到集群中生成ConfigMap；

kubeadm config upload from-flags：由配置参数生成ConfigMap；

kubeadm config view：查看当前集群中的配置值；

kubeadm config print init-defaults：输出kubeadm init默认参数文件的内容；

kubeadm config print join-defaults：输出kubeadm join默认参数文件的内容；

kubeadm config migrate：在新旧版本之间进行配置转换；

kubeadm config images list：列出所需的镜像列表；

kubeadm config images pull：拉取镜像到本地；



配置kubeadm的参数自动补全

```shell
# 查看completion帮助
kubeadm completion -h

# 配置自动补全
source <(kubeadm completion bash)
echo "source <(kubeadm completion bash)" >> ~/.bashrc
source ~/.bashrc 
```



生成配置文件

```shell
kubeadm config print init-defaults >  init-defaults.yaml
vim init-defaults.yaml修改：
	clusterName: Cluster01	
	advertiseAddress: 172.24.51.176
	name: master01
	imageRepository: registry.aliyuncs.com/google_containers

# 在init-defaults文件的结尾添加以下内容，设置kubernetes的cgroupDriver为systemd
---
kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
cgroupDriver: systemd
```

执行初始化操作

```shell
kubeadm init --config init-defaults.yaml
```

或者

```shell
kubeadm init --apiserver-advertise-address=172.24.205.51 --image-repository=registry.aliyuncs.com/google_containers
# 执行完初始化保存最后输出的结果到文件：管理用户配置、部署网络、添加节点相关信息.如果在初始化集群的时候出现报错，请执行   kubeadm reset  命令执行重置，解决提示的报错后在执行初始化操作。
```

### **1.2.2 kubectl配置文件**

root用户

```shell
echo "export KUBECONFIG=/etc/kubernetes/admin.conf" >> /root/.bashrc
source /root/.bashrc
```



非root用户

```shell
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```



### **1.2.3 kubectl参数自动补全**

查看completion帮助

```shell
kubectl completion -h
```



kubectl自动补全添加到当前shell

```shell
source <(kubectl completion bash)
echo "source <(kubectl completion bash)" >> ~/.bashrc
source ~/.bashrc 
```



### **1.2.4 Kubernetes网络**

```shell
kubectl apply -f https://docs.projectcalico.org/v3.23/manifests/calico.yaml

# 指定网卡名称
kubectl -n kube-system edit daemonsets.apps calico-node
spec:
  containers:
  - env:
    - name: IP_AUTODETECTION_METHOD  # 添加该环境变量
      value: interface=eth0    # 指定内网网卡名称，按事实情况修改
```



### **1.2.5 Nodes资源管理**

#### **1.2.5.1 添加Node节点**

```shell
# 创建token,并生成添加计算节点命令 （Master01节点执行）
 kubeadm token create --print-join-command
 ## 输出的添加节点的join命令，在计算节点执行

# 永久token
kubeadm token create --ttl 0

# 查看token （Master01节点执行）
kubeadm token list

# 获取discovery-token-ca-cert-hash值（Master01节点执行）
openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | \
   openssl dgst -sha256 -hex | sed 's/^.* //'

# 添加work节点到kubernetes集群（work node节点执行）
kubeadm join <api-server-ip:port> --token <toke> --discovery-token-ca-cert-hash sha256:<discovery-token-ca-cert-hash>
```



```shell
kubeadm token create --print-join-command 
# 自动生成以下命令，直接加入节点
kubeadm join 172.21.184.81:6443 --token jde7q3.bv4ehxnyxfe04m56     --discovery-token-ca-cert-hash sha256:cde3bc85a4fbc5bdb0e78a532d0fa0fbc301485f7d86806c06ea59f6f9610032
```



#### **1.2.5.2 删除master节点**

```shell
# 删除/etc/kubernetes目录
rm -rf /etc/kubernetes/

# ssh到<node_name>执行清理残留操作
kubeadm reset

# 删除残留目录
rm -rf /var/lib/etcd /var/lib/kubelet /var/lib/dockershim /var/run/kubernetes /var/lib/cni  /etc/cni/net.d

# 清理Iptables
iptables -F && iptables -t nat -F && iptables -t mangle -F && iptables -X

或者

# 清理IPVS
ipvsadm -C
```

#### **1.2.5.3 删除计算节点**

```shell
# 在master节点执行操作删除节点master
kubectl delete nodes <node_name>

------ 以下步骤在计算节点执行操作 ------
# 删除/etc/kubernetes目录
rm -rf /etc/kubernetes/

# ssh到<node_name>执行清理残留操作
kubeadm reset

# 删除残留目录
rm -rf /var/lib/kubelet /var/lib/dockershim /var/run/kubernetes /var/lib/cni  /etc/cni/net.d

# 清理Iptables
iptables -F && iptables -t nat -F && iptables -t mangle -F && iptables -X

或者

# 清理IPVS
ipvsadm -C
```

## **1.3 验证**

```shell
# 查看集群节点状态
kubectl get nodes

# 检查组件状态是否正常
kubectl get componentstatuses   

# 查看集群系统信息
kubectl cluster-info

# 查看核心组件是否运行正常（Running）
kubectl -n kube-system get pod
```

​       

